{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /opt/conda/envs/python39/lib/python3.9/site-packages (0.18.3)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (2.10.1)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (1.7.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (2021.10.12)\n",
      "Requirement already satisfied: networkx>=2.0 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (2.6.3)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (1.1.1)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (8.3.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/python39/lib/python3.9/site-packages (from scikit-image) (1.21.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/python39/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/envs/python39/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python39/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python39/lib/python3.9/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.3.2)\n",
      "Requirement already satisfied: six in /opt/conda/envs/python39/lib/python3.9/site-packages (from cycler>=0.10->matplotlib!=3.0.0,>=2.0.0->scikit-image) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_maps(keypoints, shape, sigma=0.1):\n",
    "    # keypoints: B x K x 2\n",
    "    # shape: H x W\n",
    "    yy, xx = torch.meshgrid(\n",
    "        torch.linspace(1, -1, shape[-2]),\n",
    "        torch.linspace(-1, 1, shape[-1]),\n",
    "    )\n",
    "    m = torch.exp(- 0.5 * ((xx[None, None, :, :] - keypoints[:, :, None, None, 0]) ** 2 + (yy[None, None, :, :] - keypoints[:, :, None, None, 1]) ** 2) / sigma ** 2)\n",
    "    return m\n",
    "\n",
    "    plt.imshow(generate_gaussian_maps())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_heatmap(image_size, center, sigma):\n",
    "    \"\"\"Creates a heatmap image with size `image_size` and a gaussian blob with `sigma` at `center`.\n",
    "\n",
    "    coord frame is origin topleft and u right, v down.\n",
    "    Args:\n",
    "        image_size: tuple with image dimensions (width, height)\n",
    "        center: tuple with center coordinate (cx, cy)\n",
    "        sigma: float\n",
    "    Returns:\n",
    "        heatmap: (w, h) heatmap image\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    u_axis = torch.linspace(0, image_size[0]-1, image_size[0]) - center[0]\n",
    "    v_axis = torch.linspace(0, image_size[1]-1, image_size[1]) - center[1]\n",
    "    # create grid values in 2D with x and y coordinate centered aroud the keypoint \n",
    "    xx, yy = torch.meshgrid(v_axis, u_axis) \n",
    "\n",
    "    ## create gaussian around the centered 2D grids $ exp ( -0.5 (x**2 + y**2) / sigma**2)$\n",
    "    heatmap = torch.exp(-0.5 * (torch.square(xx) + torch.square(yy)) / torch.square(sigma))\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c039be4f0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Demonstration on why one should use max(.) instead of sum to combine the keypoints\n",
    "# sum wil make 1 blob of 2 neighbouring keypoints\n",
    "# furthermore it will also reduce the \n",
    "img = gaussian_heatmap((32,32),(8,25),torch.Tensor([4]))\n",
    "img2 = gaussian_heatmap((32,32),(12,25),torch.Tensor([4]))\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(img  +img2)\n",
    "axarr[1].imshow(torch.max(img, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c02fb32e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_keypoints_heatmap(image_size, keypoints, sigma):\n",
    "    \"\"\"\n",
    "    Generates heatmap with gaussian blobs for each keypoint, using the given sigma.\n",
    "    Max operation is used to combine the heatpoints \n",
    "    Origin is topleft corner and u goes right, v down.\n",
    "\n",
    "    image_size: (int,int) that specify (W,H) of the heatmap image\n",
    "    keypoints: List((int,int)) with keypoints (u,v). \n",
    "    sigma: (float) std deviation of the blobs\n",
    "\n",
    "    returns a np array of the heatmap\n",
    "    \"\"\"\n",
    "    img = torch.zeros(image_size)\n",
    "    sigma = torch.Tensor([sigma])\n",
    "    for keypoint in keypoints:\n",
    "        img = torch.maximum(img,gaussian_heatmap(image_size, keypoint, sigma)) # piecewise max of 2 Tensors\n",
    "    return img\n",
    "\n",
    "heatmap = generate_keypoints_heatmap((32,32), [(4,10), (12, 25), (30,30)], 2)\n",
    "plt.imshow(heatmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4 10]\n",
      " [12 25]\n",
      " [30 30]]\n"
     ]
    }
   ],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "import numpy as np\n",
    "\n",
    "def get_keypoints_from_heatmap(heatmap: np.ndarray, min_keypoint_pixel_distance):\n",
    "    \"\"\" \n",
    "    Returns a list of (u,v) coordinates of the keypoints\n",
    "\n",
    "    heatmap: a np 2D array\n",
    "    min_keypoint_pixel_distance: minimum distance between 2 keypoints, so the area in which the keypoint has to be the local max is 2*min_distance + 1\n",
    "\n",
    "    cf https://scikit-image.org/docs/dev/api/skimage.feature.html#skimage.feature.peak_local_max\n",
    "    \"\"\"\n",
    "    np_heatmap = heatmap.numpy()\n",
    "    keypoints = peak_local_max(np_heatmap, min_distance = min_keypoint_pixel_distance)\n",
    "    return keypoints[::,::-1] # convert to (u,v) aka (col,row) coord frame from (row,col) \n",
    "\n",
    "print (get_keypoints_from_heatmap(heatmap,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from torchvision.transforms import ToTensor\n",
    "import os \n",
    "\n",
    "class BoxKeypointsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Create Custom Pytorch Dataset from the Box dataset\n",
    "    cf https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "    \"\"\"\n",
    "    def __init__(self,json_file, image_dir):\n",
    "        \"\"\"\n",
    "        json_file  path to json file with dataset\n",
    "        image_dir: path to dir from where the relative image paths in the json are included\n",
    "        transform: torch transforms to apply to the images before using them \n",
    "        \"\"\"\n",
    "\n",
    "        self.json_file = json_file\n",
    "        self.image_dir = image_dir\n",
    "\n",
    "        self.dataset  = None  # List of dicts with 'image_path', 'corner_keypoint' and 'flap_keypoints' keys for each item\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        if torch.is_tensor(index):\n",
    "            index = index.tolist()\n",
    "        index = int(index)\n",
    "\n",
    "        image_path = os.path.join(self.image_dir, self.dataset[index]['image_path'])\n",
    "        image = io.imread(image_path)\n",
    "        image = ToTensor(image)\n",
    "        \n",
    "        corner_keypoints = self.dataset[index]['corner_keypoints']\n",
    "        flap_keypoints = self.dataset[index]['flap_keypoints']\n",
    "\n",
    "        return image, corner_keypoints, flap_keypoints\n",
    "    \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoxKeypointsDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, dataset: BoxKeypointsDataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "        #TODO: split in test and train set\n",
    "        self.train_dataset = dataset\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # done in dataset class\n",
    "        pass\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataloader = DataLoader(self.train_dataset, self.batch_size, shuffle=True, num_workers=4)\n",
    "        return dataloader\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    plot Tensor as image\n",
    "    images are kept in the [0,1] range, although in theory [-1,1] should be used to whiten..\n",
    "    \"\"\"\n",
    "    np_img = img.numpy()\n",
    "    # bring (C,W,H) to (W,H,C) dims\n",
    "    img = np.transpose(np_img, (1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "class KeypointDetector(pl.LightningModule):\n",
    "    \"\"\" \n",
    "    Simple keypoint Detector using Gaussian Channels\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.heatmap_sigma = 4 \n",
    "\n",
    "\n",
    "        n_channels = 32\n",
    "        n_channels_in = 3\n",
    "        n_channels_out = 1 # number of keypoint classes \n",
    "        kernel_size = (3,3)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_channels_in, out_channels=n_channels, kernel_size=kernel_size, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, dilation=2, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, dilation=4, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, dilation=8, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,dilation=16, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, dilation=2, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, dilation=4, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, dilation=8, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size,dilation=16, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding='same'),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels_out, kernel_size=kernel_size, padding='same'),\n",
    "            nn.Sigmoid()\n",
    "        ).to(self.device)\n",
    "\n",
    "    def forward(self,x):\n",
    "        \"\"\"\n",
    "        x shape must be (N,C_in,H,W) with N batch size, and C_in number of incoming channels (3)\n",
    "        return shape = (N, 1, H,W)\n",
    "        \"\"\"\n",
    "        return self.model(x)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        return optimizer\n",
    "\n",
    "    def loss(self, predicted_heatmaps, heatmaps):\n",
    "        # No focal loss as in CenterNet paper bc @Peter said it does not improve performance too much, so KISS and maybe add it later\n",
    "        return torch.nn.functional.binary_cross_entropy(predicted_heatmaps, heatmaps, reduction='mean')\n",
    "    \n",
    "    def create_heatmap_batch(self, shape, keypoints):\n",
    "        batch_heatmaps = [ generate_keypoints_heatmap(shape, keypoints[i],self.heatmap_sigma) for i in range(len(keypoints))]\n",
    "        batch_heatmaps = np.stack(batch_heatmaps, axis=0)\n",
    "        batch_heatmaps = torch.from_numpy(batch_heatmaps)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        imgs, corner_keypoints, flap_keypoints = train_batch\n",
    "\n",
    "        # load here to device to keep mem consumption low, if possible one could also load entire dataset on GPU to speed up training..\n",
    "        imgs = imgs.to(self.device)\n",
    "        # create heatmaps JIT, is this desirable? \n",
    "        corner_heatmaps = self.create_heatmap_batch(img[0].shape[1:], corner_keypoints,self.heatmap_sigma).to(self.device)\n",
    "        #flap_heatmaps = self.create_heatmap_batch(img[0].shape[1:], flap_keypoints,self.heatmap_sigma).to(self.device)\n",
    "\n",
    "\n",
    "        predicted_heatmaps = self.foward(imgs)\n",
    "        predicted_corner_heatmaps = predicted_heatmaps[:,0,:,:]\n",
    "\n",
    "        corner_loss = self.loss(predicted_corner_heatmaps, corner_heatmaps)\n",
    "\n",
    "        loss = corner_loss\n",
    "\n",
    "        ## logging\n",
    "        self.log('train_corner_loss', corner_loss)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 180, 180])\n",
      "KeypointDetector(\n",
      "  (model): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (1): LeakyReLU(negative_slope=0.01)\n",
      "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (3): LeakyReLU(negative_slope=0.01)\n",
      "    (4): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "    (5): LeakyReLU(negative_slope=0.01)\n",
      "    (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(4, 4))\n",
      "    (7): LeakyReLU(negative_slope=0.01)\n",
      "    (8): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(8, 8))\n",
      "    (9): LeakyReLU(negative_slope=0.01)\n",
      "    (10): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(16, 16))\n",
      "    (11): LeakyReLU(negative_slope=0.01)\n",
      "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (13): LeakyReLU(negative_slope=0.01)\n",
      "    (14): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(2, 2))\n",
      "    (15): LeakyReLU(negative_slope=0.01)\n",
      "    (16): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(4, 4))\n",
      "    (17): LeakyReLU(negative_slope=0.01)\n",
      "    (18): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(8, 8))\n",
      "    (19): LeakyReLU(negative_slope=0.01)\n",
      "    (20): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, dilation=(16, 16))\n",
      "    (21): LeakyReLU(negative_slope=0.01)\n",
      "    (22): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (23): LeakyReLU(negative_slope=0.01)\n",
      "    (24): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
      "    (25): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = KeypointDetector()\n",
    "dummy_input = torch.rand((1,3,180,180))\n",
    "\n",
    "output = model(dummy_input)\n",
    "print(output.shape)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "model = KeypointDetector()\n",
    "box_dataset = BoxKeypointsDataset(\"json\",\"image_dir\")\n",
    "datamodule = BoxKeypointsDataModule(box_dataset)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, datamodule)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f906b64a0d5d4d6115edb742e7cca7ea3d71b0e470c6accd3a055dd1e62d03fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('python39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
