{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook shows some functionalities of the package. For training, please use the train.py file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch \n",
    "import numpy as np \n",
    "from keypoint_detection.src.keypoint_utils import gaussian_heatmap, generate_keypoints_heatmap, get_keypoints_from_heatmap\n",
    "from keypoint_detection import KeypointDetector\n",
    "from keypoint_detection import BoxKeypointsDataModule, BoxKeypointsDataset, DatasetPreloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb_logger = WandbLogger(project=\"test-project\", entity=\"airo-box-manipulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstration on why one should use max(.) instead of sum to combine the keypoints\n",
    "# sum wil make 1 blob of 2 neighbouring keypoints\n",
    "# furthermore it will also reduce the \n",
    "img = gaussian_heatmap((32,50),(8,25),torch.Tensor([4]))\n",
    "img2 = gaussian_heatmap((32,50),(12,25),torch.Tensor([4]))\n",
    "\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(img  +img2)\n",
    "axarr[1].imshow(torch.max(img, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATASET_PATH = \"/workspaces/box-manipulation/datasets/box_dataset2\"\n",
    "JSON_PATH = \"/workspaces/box-manipulation/datasets/box_dataset2/dataset.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    plot Tensor as image\n",
    "    images are kept in the [0,1] range, although in theory [-1,1] should be used to whiten..\n",
    "    \"\"\"\n",
    "    np_img = img.numpy()\n",
    "    # bring (C,W,H) to (W,H,C) dims\n",
    "    img = np.transpose(np_img, (1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap_overlay(img, heatmap):\n",
    "    \"\"\"\n",
    "    plot Tensors of heatmap and image on same figure \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()  #create figure and axes\n",
    "    img = img.numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    ax.imshow(img, alpha= 0.9)\n",
    "    ax.imshow(heatmap.numpy(), alpha = 0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test caching influence\n",
    "\n",
    "dataset = BoxKeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH)\n",
    "\n",
    "preloaded_dataset = DatasetPreloader(dataset, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dataset)):\n",
    "    a = dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(preloaded_dataset)):\n",
    "    a = preloaded_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "module = BoxKeypointsDataModule(BoxKeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH),2)\n",
    "batch = next(iter(module.train_dataloader()))\n",
    "#print(batch)\n",
    "print(batch[0].shape)\n",
    "print(batch[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeypointDetector(heatmap_sigma= 8)\n",
    "dummy_input = torch.rand((1,3,180,180))\n",
    "\n",
    "output = model(dummy_input)\n",
    "print(output.shape)\n",
    "print(model)\n",
    "\n",
    "module = BoxKeypointsDataModule(BoxKeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH),2)\n",
    "batch = next(iter(module.train_dataloader()))\n",
    "imgs, corner_keypoints, flap_keypoints = batch \n",
    "print(imgs[0].shape[1:])\n",
    "print(imgs.shape)\n",
    "\n",
    "heatmaps = model.create_heatmap_batch(imgs[0].shape[1:],corner_keypoints)\n",
    "flap_heatmaps = model.create_heatmap_batch(imgs[0].shape[1:], flap_keypoints)\n",
    "print(heatmaps.shape)\n",
    "show_heatmap_overlay(imgs[0],heatmaps[0])\n",
    "show_heatmap_overlay(imgs[0],flap_heatmaps[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(2021, workers = True) # deterministic run\n",
    "model = KeypointDetector(detect_flap_keypoints=False)\n",
    "module = BoxKeypointsDataModule(BoxKeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH),2)\n",
    "print(len(module.val_dataloader()))\n",
    "print(len(module.train_dataloader()))\n",
    "trainer = pl.Trainer(max_epochs = 1, logger=wandb_logger, gpus=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(module.train_dataloader()))\n",
    "\n",
    "imgs, corner_keypoints, flap_keypoints = batch \n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(imgs)\n",
    "    show_heatmap_overlay(imgs[0],predictions[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f906b64a0d5d4d6115edb742e7cca7ea3d71b0e470c6accd3a055dd1e62d03fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('python39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
