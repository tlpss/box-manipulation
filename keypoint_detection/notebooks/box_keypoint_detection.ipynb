{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook shows some functionalities of the package. For training, please use the train.py file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch \n",
    "import numpy as np \n",
    "from keypoint_detection.utils.heatmap import gaussian_heatmap, generate_keypoints_heatmap, get_keypoints_from_heatmap\n",
    "from keypoint_detection.models.detector import KeypointDetector\n",
    "from keypoint_detection.data.datamodule import RandomSplitDataModule\n",
    "from keypoint_detection.data.dataset import  KeypointsDataset, KeypointsDatasetPreloaded\n",
    "from keypoint_detection.models.loss import bce_loss\n",
    "from keypoint_detection.models.backbones.dilated_cnn import DilatedCnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to run `wandb login` in your terminal\n",
    "wandb_logger = WandbLogger(project=\"test-project\", entity=\"airo-box-manipulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstration on why one should use max(.) instead of sum to combine the keypoints\n",
    "# sum wil make 1 blob of 2 neighbouring keypoints\n",
    "# furthermore it will also reduce the \n",
    "img = gaussian_heatmap((32,50),(8,25),torch.Tensor([4]),\"cpu\")\n",
    "img2 = gaussian_heatmap((32,50),(12,25),torch.Tensor([4]),\"cpu\")\n",
    "print(torch.max(img)) # max (at location of keypoint) should be 1!\n",
    "f, axarr = plt.subplots(1,2)\n",
    "axarr[0].imshow(img  +img2)\n",
    "axarr[1].imshow(torch.max(img, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DATASET_PATH = \"/workspaces/box-manipulation/keypoint_detection/datasets/box_dataset2\"\n",
    "JSON_PATH = \"/workspaces/box-manipulation/keypoint_detection/datasets/box_dataset2/dataset.json\"\n",
    "CHANNELS = \"corner_keypoints\"\n",
    "CHANNEL_SIZE =\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    plot Tensor as image\n",
    "    images are kept in the [0,1] range, although in theory [-1,1] should be used to whiten..\n",
    "    \"\"\"\n",
    "    np_img = img.numpy()\n",
    "    # bring (C,W,H) to (W,H,C) dims\n",
    "    img = np.transpose(np_img, (1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap_overlay(img, heatmap):\n",
    "    \"\"\"\n",
    "    plot Tensors of heatmap and image on same figure \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()  #create figure and axes\n",
    "    img = img.numpy()\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    ax.imshow(img, alpha= 0.9)\n",
    "    ax.imshow(heatmap.numpy(), alpha = 0.2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset strategies for minimizing memory footprint and runtime delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## test caching influence\n",
    "\n",
    "dataset = KeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH,CHANNELS, CHANNEL_SIZE)\n",
    "preloaded_dataset = KeypointsDatasetPreloaded(JSON_PATH, IMAGE_DATASET_PATH,CHANNELS, CHANNEL_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    batch = dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    batch_preloaded = preloaded_dataset[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show why to keep np in memory and not torch Tensor.\n",
    "import sys\n",
    "print(preloaded_dataset[0][0].dtype)\n",
    "print(preloaded_dataset.preloaded_images[0].dtype)\n",
    "# get torch tensor memory size -> \n",
    "print(f\" torch image size = {sys.getsizeof(preloaded_dataset[0][0].storage())}\")\n",
    "print(f\" expected torch image size = {256*256*3*4}\") # float32!\n",
    "# get numpy array memory size -> \n",
    "print(preloaded_dataset.preloaded_images[0].nbytes) # uint8\n",
    "print(256*256*3*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show output of batch\n",
    "\n",
    "module = RandomSplitDataModule(KeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH,CHANNELS, CHANNEL_SIZE),2,0.25,2)\n",
    "batch = next(iter(module.train_dataloader()))\n",
    "#print(batch)\n",
    "\n",
    "## batch: tuple (IMG, Keypoints)\n",
    "## img is a (B,C,W,H) tensor\n",
    "## keypoints is a List of channels\n",
    "## where each item is of shape (B,N,2/3)\n",
    "print(len(batch[0]))\n",
    "img, keypoints = batch\n",
    "print(img.shape)\n",
    "print(len(keypoints))\n",
    "print(keypoints[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show model input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(2021, workers = True) # deterministic run\n",
    "model = KeypointDetector(heatmap_sigma=2,maximal_gt_keypoint_pixel_distances=\"2\",minimal_keypoint_extraction_pixel_distance=1,learning_rate=3e-4,backbone=DilatedCnn(),loss_function=bce_loss, keypoint_channels=CHANNELS,ap_epoch_freq=4,ap_epoch_start=10)\n",
    "dataset = KeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH,CHANNELS, CHANNEL_SIZE)\n",
    "module = RandomSplitDataModule(dataset,batch_size = 4, validation_split_ratio= 0.1,num_workers= 2)\n",
    "dummy_input = torch.rand((1,3,180,180))\n",
    "\n",
    "output = model(dummy_input)\n",
    "print(output.shape)\n",
    "print(model)\n",
    "\n",
    "\n",
    "batch = next(iter(module.train_dataloader()))\n",
    "imgs, keypoints = batch \n",
    "print(imgs[0].shape[1:])\n",
    "print(imgs.shape)\n",
    "\n",
    "heatmaps = model.create_heatmap_batch(imgs[0].shape[1:],keypoints[0])\n",
    "flap_heatmaps = model.create_heatmap_batch(imgs[0].shape[1:], keypoints[0])\n",
    "print(heatmaps.shape)\n",
    "show_heatmap_overlay(imgs[0],heatmaps[0])\n",
    "show_heatmap_overlay(imgs[0],flap_heatmaps[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(2021, workers = True) # deterministic run\n",
    "model = KeypointDetector(heatmap_sigma=2,maximal_gt_keypoint_pixel_distances=\"2\",minimal_keypoint_extraction_pixel_distance=1,learning_rate=3e-4,backbone=DilatedCnn(),loss_function=bce_loss, keypoint_channels=CHANNELS,ap_epoch_freq=4,ap_epoch_start=10)\n",
    "dataset = KeypointsDataset(JSON_PATH, IMAGE_DATASET_PATH,CHANNELS, CHANNEL_SIZE)\n",
    "module = RandomSplitDataModule(dataset,batch_size = 4, validation_split_ratio= 0.1,num_workers= 2)\n",
    "# number of batches!\n",
    "print(len(module.val_dataloader()))\n",
    "print(len(module.train_dataloader()))\n",
    "trainer = pl.Trainer(max_epochs = 1, logger=wandb_logger, gpus=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%wandb\n",
    "trainer.fit(model, module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Take a look at the model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(module.train_dataloader()))\n",
    "\n",
    "imgs, keypoints = batch \n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    predictions = model(imgs)\n",
    "    heatmaps = model.create_heatmap_batch(imgs[0].shape[1:],keypoints[0])\n",
    "    show_heatmap_overlay(imgs[0], heatmaps[0])\n",
    "    show_heatmap_overlay(imgs[0],predictions[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f906b64a0d5d4d6115edb742e7cca7ea3d71b0e470c6accd3a055dd1e62d03fb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('python39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
