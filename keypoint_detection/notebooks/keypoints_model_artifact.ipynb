{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning import Trainer\n",
    "import torch\n",
    "import numpy as np\n",
    "from keypoint_detection.utils.heatmap import gaussian_heatmap, generate_keypoints_heatmap, overlay_image_with_heatmap, get_keypoints_from_heatmap\n",
    "from keypoint_detection.models.detector import KeypointDetector\n",
    "from keypoint_detection.data.unlabeled_dataset import UnlabeledBoxDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Get Model checkpoint from wandb\n",
    "\n",
    "\n",
    "checkpoint_reference = \"airo-box-manipulation/box_dataset_04_02/model-k3plhnyf:latest\"\n",
    "\n",
    "# download checkpoint locally (if not already cached)\n",
    "run = wandb.init(project=\"test-project\", entity=\"airo-box-manipulation\")\n",
    "artifact = run.use_artifact(checkpoint_reference, type=\"model\")\n",
    "artifact_dir = artifact.download()\n",
    "\n",
    "# \n",
    "checkpoint = torch.load(Path(artifact_dir) / \"model.ckpt\")\n",
    "print(checkpoint[\"hyper_parameters\"])\n",
    "# load checkpoint\n",
    "model = KeypointDetector.load_from_checkpoint(Path(artifact_dir) / \"model.ckpt\", backbone='Unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_DIR = UnlabeledBoxDataset.get_data_dir_path() / \"real_data_2021_12_09\"\n",
    "JSON_PATH = UnlabeledBoxDataset.get_data_dir_path() / \"real_data_2021_12_09\" / \"dataset.json\"\n",
    "dataset = UnlabeledBoxDataset(JSON_PATH,IMAGE_DIR)\n",
    "print(len(dataset))\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size= 8, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    \"\"\"\n",
    "    plot Tensor as image\n",
    "    images are kept in the [0,1] range, although in theory [-1,1] should be used to whiten..\n",
    "    \"\"\"\n",
    "    np_img = img.numpy()\n",
    "    # bring (C,W,H) to (W,H,C) dims\n",
    "    img = np.transpose(np_img, (1,2,0))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transform  = torchvision.transforms.Resize((256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def show_results(type = \"corner\", show_extracted_keypoints = True, mode =\"eval\"):\n",
    "    \"\"\"\n",
    "    show network outputs on the dataset.\n",
    "    \"\"\"\n",
    "    plt.rcParams[\"figure.figsize\"] = (20,3)\n",
    "    pil_to_torch = torchvision.transforms.ToTensor()\n",
    "    if mode == \"eval\":\n",
    "        model.eval()\n",
    "    else:\n",
    "        model.train()\n",
    "    for batch in iter(dataloader):\n",
    "        with torch.no_grad():\n",
    "            batch = transform(batch)\n",
    "            channel = 1 if type == \"flap\" else 0\n",
    "            output = model(batch)[:,channel]\n",
    "            if not show_extracted_keypoints:\n",
    "                overlayed_heatmap = torch.stack(\n",
    "                    [\n",
    "                        pil_to_torch(overlay_image_with_heatmap(batch[i], torch.unsqueeze(output[i].cpu(), 0),0.6))\n",
    "                        for i in range(batch.shape[0])\n",
    "                    ]\n",
    "                )\n",
    "            else:\n",
    "                n_keypoints = 4 if type == \"corner\" else 8\n",
    "                overlayed_heatmap = torch.stack(\n",
    "                [\n",
    "                    pil_to_torch(\n",
    "                        overlay_image_with_heatmap(\n",
    "                            batch[i],\n",
    "                            torch.unsqueeze(\n",
    "                                generate_keypoints_heatmap(\n",
    "                                    batch.shape[-2:],\n",
    "\n",
    "                                    get_keypoints_from_heatmap(output[i].cpu(), 1,n_keypoints),\n",
    "                                    sigma=2,\n",
    "                                    device = 'cpu'\n",
    "                                ),\n",
    "                                0,\n",
    "                            ),\n",
    "                            0.6\n",
    "                        )\n",
    "                    )\n",
    "                    for i in range(batch.shape[0])\n",
    "                ]\n",
    "        )\n",
    "        grid = torchvision.utils.make_grid(overlayed_heatmap, nrow=8)\n",
    "        imshow(grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_results(\"corner\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "show_results(\"flap\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
